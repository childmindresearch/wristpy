{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e \"/Users/adam.santorelli/lib/wristpy/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/Users/adam.santorelli/Downloads/raw_gt3x_data_archive/NDARPJ763DV1.gt3x'\n",
    "output_path = '/Users/adam.santorelli/Downloads/raw_gt3x_data_archive/NDARPJ763DV1_output/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import polars as pl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import wristpy\n",
    "from wristpy.common import data_model\n",
    "from wristpy.ggir import calibration, compare_dataframes, metrics_calc, error_tests\n",
    "from wristpy.io.loaders import gt3x\n",
    "\n",
    "warnings.filterwarnings(\"always\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = \"/Users/adam.santorelli/Downloads/raw_gt3x_data_archive/\"\n",
    "ggir_path = \"/Users/adam.santorelli/Downloads/ggir_raw_outputs_group1/\"\n",
    "\n",
    "file_name = [os.path.splitext(os.path.basename(file))[0] for file in glob.glob(file_path + \"*.gt3x\")]\n",
    "dir_name = [os.path.dirname(file) for file in glob.glob(ggir_path + \"*.gt3x\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(error_tests)\n",
    "importlib.reload(metrics_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, dir in zip(file_name, dir_name):\n",
    "    input_path = dir + \"/\" + file + \".gt3x\"\n",
    "    output_path = dir + \"/\" + file + \"_output/\"\n",
    "    wristpy_out = error_tests.process_file(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(wristpy_out.battery_upsample_epoch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wristpy.ggir import error_tests_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "file_path = \"/Users/adam.santorelli/Downloads/wristpy_out/\"\n",
    "ggir_path = \"/Users/adam.santorelli/Downloads/ggir_raw_outputs/\"\n",
    "\n",
    "file_name = [os.path.splitext(os.path.basename(file))[0] for file in glob.glob(file_path + \"**/*_metrics_out.csv\", recursive=True)]\n",
    "dir_name =  [os.path.dirname(file) for file in glob.glob(file_path + \"**/*_metrics_out.csv\", recursive=True)]\n",
    "#ggir_file_name = [os.path.splitext(os.path.basename(file))[0] for file in glob.glob(ggir_path + \"**/*.csv\", recursive=True)]\n",
    "\n",
    "file_name_sorted = sorted(file_name)\n",
    "dir_name_sorted = sorted(dir_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(error_tests)\n",
    "importlib.reload(metrics_calc)\n",
    "importlib.reload(error_tests_local)\n",
    "importlib.reload(compare_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_sorted[0], dir_name_sorted[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAA408JMA_output/NDARAA408JMA_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAA773LUW_output/NDARAA773LUW_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAA948VFH_output/NDARAA948VFH_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAB055BPR_output/NDARAB055BPR_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAB348EWR_output/NDARAB348EWR_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAB653ZXP_output/NDARAB653ZXP_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAB696MF4_output/NDARAB696MF4_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAB708LM5_output/NDARAB708LM5_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAB756JDJ_output/NDARAB756JDJ_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAC350BZ0_output/NDARAC350BZ0_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAC350XUM_output/NDARAC350XUM_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAC495TJ2_output/NDARAC495TJ2_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAC688ZM5_output/NDARAC688ZM5_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAC853DTE_output/NDARAC853DTE_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAC923GPW_output/NDARAC923GPW_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAC973ENV_output/NDARAC973ENV_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAD123TUZ_output/NDARAD123TUZ_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAD615WLJ_output/NDARAD615WLJ_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAD774HAZ_output/NDARAD774HAZ_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAE004LZJ_output/NDARAE004LZJ_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAE301XTM_output/NDARAE301XTM_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAE358VBE_output/NDARAE358VBE_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAE540FCG_output/NDARAE540FCG_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAE828CML_output/NDARAE828CML_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAE839XXL_output/NDARAE839XXL_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAE854KGZ_output/NDARAE854KGZ_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAE877NER_output/NDARAE877NER_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAG943DF9_output/NDARAG943DF9_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAH239PGG_output/NDARAH239PGG_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAH304ED7_output/NDARAH304ED7_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAH373VWM_output/NDARAH373VWM_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAH503YG1_output/NDARAH503YG1_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAH793FBF_output/NDARAH793FBF_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAJ689BVN_output/NDARAJ689BVN_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAK078LMR_output/NDARAK078LMR_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAK738BGC_output/NDARAK738BGC_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAK770XEW_output/NDARAK770XEW_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAM420CU7_output/NDARAM420CU7_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAM848GTE_output/NDARAM848GTE_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAM873GAC_output/NDARAM873GAC_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAN229MTX_output/NDARAN229MTX_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAN262WK6_output/NDARAN262WK6_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAP120HTA_output/NDARAP120HTA_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAP158KB3_output/NDARAP158KB3_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAP522AFK_output/NDARAP522AFK_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAP785CTE_output/NDARAP785CTE_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAR160ZPZ_output/NDARAR160ZPZ_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAR335FZH_output/NDARAR335FZH_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAR537GD3_output/NDARAR537GD3_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAR630RFB_output/NDARAR630RFB_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAR935TGZ_output/NDARAR935TGZ_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAR991JAA_output/NDARAR991JAA_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAR998KMM_output/NDARAR998KMM_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAT000LDV_output/NDARAT000LDV_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAT244VGA_output/NDARAT244VGA_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAT287CJE_output/NDARAT287CJE_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAT358XM9_output/NDARAT358XM9_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAT680GJA_output/NDARAT680GJA_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAT696TMM_output/NDARAT696TMM_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAU708TL8_output/NDARAU708TL8_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAV519RND_output/NDARAV519RND_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAV925BP3_output/NDARAV925BP3_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAX272ZJL_output/NDARAX272ZJL_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAX277ATU_output/NDARAX277ATU_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAX283MAK_output/NDARAX283MAK_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAX358NB5_output/NDARAX358NB5_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAX431KJ2_output/NDARAX431KJ2_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAX887JRN_output/NDARAX887JRN_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAY006MJB_output/NDARAY006MJB_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAY021PPD_output/NDARAY021PPD_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARAY461TZZ_output/NDARAY461TZZ_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARBB118UDB_output/NDARBB118UDB_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARBB542URX_output/NDARBB542URX_metrics_out.csv\n",
      "/Users/adam.santorelli/Downloads/wristpy_out/NDARBC202FT0_output/NDARBC202FT0_metrics_out.csv\n"
     ]
    },
    {
     "ename": "ComputeError",
     "evalue": "could not parse `20.0632` as dtype `i64` at column 'anglez' (column number 2)\n\nThe current offset in the file is 17967410 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `dtypes` argument\n- setting `ignore_errors` to `True`,\n- adding `20.0632` to the `null_values` list.\n\nOriginal error: ```remaining bytes non-empty```",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5w/nz07xc215vv587tk6xcmwdg40000gq/T/ipykernel_84118/2778786992.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mggir_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mggir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mggir_file_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".gt3x.RData.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mggir_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mwristpy_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mggir_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_dataframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_ggir_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mggir_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Compute errors and append to errors_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_tests_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwristpy_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mggir_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/wristpy/src/wristpy/ggir/compare_dataframes.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mpolars\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mGGIR\u001b[0m \u001b[0menmo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manglez\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mTimestamps\u001b[0m \u001b[0mhave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mbeen\u001b[0m \u001b[0msliced\u001b[0m \u001b[0mto\u001b[0m \u001b[0mremove\u001b[0m \u001b[0mtimezone\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \"\"\"\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mggir_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ENMO\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloat64\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mggir_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mggir_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mggir_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/polars/utils/deprecation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             _rename_keyword_argument(\n\u001b[1;32m    134\u001b[0m                 \u001b[0mold_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/polars/utils/deprecation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             _rename_keyword_argument(\n\u001b[1;32m    134\u001b[0m                 \u001b[0mold_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/polars/utils/deprecation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             _rename_keyword_argument(\n\u001b[1;32m    134\u001b[0m                 \u001b[0mold_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/polars/io/csv/functions.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(source, has_header, columns, new_columns, separator, comment_prefix, quote_char, skip_rows, dtypes, schema, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, use_pyarrow, storage_options, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0muse_pyarrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mraise_if_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_if_empty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     ) as data:\n\u001b[0;32m--> 397\u001b[0;31m         df = pl.DataFrame._read_csv(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mhas_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/polars/dataframe/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, source, has_header, columns, separator, comment_prefix, quote_char, skip_rows, dtypes, schema, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines)\u001b[0m\n\u001b[1;32m    763\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mprojection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_projection_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m         self._df = PyDataFrame.read_csv(\n\u001b[0m\u001b[1;32m    768\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0minfer_schema_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mComputeError\u001b[0m: could not parse `20.0632` as dtype `i64` at column 'anglez' (column number 2)\n\nThe current offset in the file is 17967410 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `dtypes` argument\n- setting `ignore_errors` to `True`,\n- adding `20.0632` to the `null_values` list.\n\nOriginal error: ```remaining bytes non-empty```"
     ]
    }
   ],
   "source": [
    "errors_out = []\n",
    "\n",
    "for file, dir in zip(file_name_sorted, dir_name_sorted):\n",
    "    input_path = dir + \"/\" + file + \".csv\"\n",
    "    ggir_file_name = os.path.basename(dir).rstrip(\"_output\") \n",
    "    ggir_file = ggir_path + ggir_file_name + \".gt3x.RData.csv\"\n",
    "    \n",
    "    if os.path.exists(ggir_file):\n",
    "        wristpy_out = pl.read_csv(input_path)\n",
    "        ggir_data = compare_dataframes.load_ggir_output(ggir_file)\n",
    "        print(input_path)\n",
    "        # Compute errors and append to errors_out\n",
    "        errors = error_tests_local.compute_error(wristpy_out, ggir_data)\n",
    "        errors_out.append(errors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggir_data = compare_dataframes.load_ggir_output(ggir_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch1_data = compare_dataframes.compare_csv(\n",
    "        ggir_dataframe=ggir_data, wristpy_dataframe=wristpy_out\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch1_data = epoch1_data.with_columns(pl.col(\"time_epoch1\").set_sorted())\n",
    "NW_flag_rolling_mean = epoch1_data.group_by_dynamic(index_column=\"time_epoch1\", every=\"3h\").agg(pl.col(\"non_wear_flag\").mean())\n",
    "NW_flag_rolling_mean = NW_flag_rolling_mean[\"non_wear_flag\"].map_elements(\n",
    "        lambda x: 1 if x > 0.25 else 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epoch1_data[\"time_epoch1\"], epoch1_data[\"enmo_wristpy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggir_time = pl.Series(ggir_data[\"timestamp\"])\n",
    "\n",
    "ggir_datetime = ggir_time.str.to_datetime(time_unit=\"ns\")\n",
    "\n",
    "epoch1_wristpy = pl.DataFrame({\"time_epoch1\": wristpy_out.time_epoch1,\n",
    "                          \"enmo_wristpy\": wristpy_out.enmo_epoch1,\n",
    "                          \"anglez_wristpy\": wristpy_out.anglez_epoch1,\n",
    "                          \"non_wear_flag\": wristpy_out.non_wear_flag_epoch1})\n",
    "\n",
    "epoch1_ggir = pl.DataFrame({\"time_epoch1\": ggir_datetime,\n",
    "                            \"enmo_ggir\": ggir_data[\"ENMO\"],\n",
    "                            \"anglez_ggir\": ggir_data[\"anglez\"]})\n",
    "\n",
    "epoch1_df_time_match = epoch1_wristpy.join(\n",
    "        epoch1_ggir, left_on=\"time_epoch1\", right_on=\"time_epoch1\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch1_df_time_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NW_flag_rolling_mean = epoch1_df_time_match[\"non_wear_flag\"].rolling_mean(\n",
    "        window_size=2160\n",
    "    )\n",
    "NW_flag_rolling_mean = NW_flag_rolling_mean.map_elements(\n",
    "        lambda x: 1 if x > 0.25 else 0\n",
    "    )\n",
    "\n",
    "metrics_calc_nonwear = epoch1_df_time_match.filter(\n",
    "        epoch1_df_time_match[\"non_wear_flag\"] == 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_calc_nonwear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics_calc_nonwear[\"time_epoch1\"], metrics_calc_nonwear[\"anglez_wristpy\"], label=\"wristpy\")\n",
    "plt.plot(metrics_calc_nonwear[\"time_epoch1\"], metrics_calc_nonwear[\"anglez_ggir\"], label=\"ggir\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( ggir_data[\"ENMO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median([row[2] for row in errors_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERAL TESTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/Users/adam.santorelli/Downloads/NDARXT222XYH.gt3x'\n",
    "output_path = '/Users/adam.santorelli/Downloads/NDARXT222XYH_output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = wristpy.common.data_model.Config(file_name, output_path)\n",
    "test_config.path_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_name = os.path.splitext(os.path.basename(test_config.path_input))[0]\n",
    "file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "last_dir_name = os.path.basename(os.path.dirname(test_config.path_output))\n",
    "last_dir_name = last_dir_name.split(\"_output\")[0]\n",
    "last_dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(data_model)\n",
    "importlib.reload(gt3x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = gt3x.load_fast(test_config.path_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wristpy.ggir import metrics_calc\n",
    "from wristpy.ggir import calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = calibration.start_ggir_calibration(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_calc.calc_base_metrics(test_output)\n",
    "metrics_calc.calc_epoch1_metrics(test_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_calc.calc_epoch1_raw(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(metrics_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_calc.set_nonwear_flag(test_output, 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_calc.calc_epoch1_light(test_data, test_output)\n",
    "metrics_calc.calc_epoch1_battery(test_data, test_output)\n",
    "metrics_calc.calc_epoch1_cap_sensor(test_data, test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.battery_upsample_epoch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(test_output.time_epoch1, test_output.non_wear_flag_epoch1, color='blue')\n",
    "ax1.set_ylabel('NW flag', color='blue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(test_output.time_epoch1, test_output.capsense_upsample_epoch1, color='red',alpha=0.5)\n",
    "ax2.set_ylabel('Cap Sensor', color='red')\n",
    "\n",
    "# Set y-axis limit to 0\n",
    "ax1.set_ylim(bottom=0)\n",
    "ax2.set_ylim(bottom=0)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_csv = pl.DataFrame({\n",
    "    \"time\": test_output.time_epoch1,\n",
    "    \"X\": test_output.accel_epoch1[\"X_mean\"],\n",
    "    \"Y\": test_output.accel_epoch1[\"Y_mean\"],\n",
    "    \"Z\": test_output.accel_epoch1[\"Z_mean\"],\n",
    "    \"enmo\": test_output.enmo_epoch1,\n",
    "    \"anglez\": test_output.anglez_epoch1,\n",
    "    \"Non-wear Flag\": test_output.non_wear_flag_epoch1,\n",
    "    \"light\": test_output.lux_epoch1,\n",
    "    \"battery voltage\": test_output.battery_upsample_epoch1,\n",
    "    \"capacitive sensor\": test_output.capsense_upsample_epoch1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_file_path = test_config.path_output + 'metrics_out.csv'\n",
    "\n",
    "# Check if the directory already exists\n",
    "if not os.path.exists(test_config.path_output):\n",
    "    os.mkdir(test_config.path_output)\n",
    "else:\n",
    "    print(\"Directory already exists.\")\n",
    "\n",
    "if os.path.exists(output_file_path):\n",
    "    # Generate a new filename, this only allows one copy of _new....\n",
    "    base_filename = os.path.basename(output_file_path)\n",
    "    filename, extension = os.path.splitext(base_filename)\n",
    "    new_filename = filename + \"_new\" + extension\n",
    "    \n",
    "    # Write the CSV file with the new filename\n",
    "    output_data_csv.write_csv(os.path.join(test_config.path_output, new_filename))\n",
    "else:\n",
    "    output_data_csv.write_csv(output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = test_config.path_output + 'metrics_out.csv'\n",
    "output_data_csv.write_csv(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GIR compare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wristpy.ggir import compare_dataframes\n",
    "ggir_file = \"/Users/adam.santorelli/Downloads/raw_gt3x_data_archive/output_NDARPJ763DV1.gt3x/meta/csv/NDARPJ763DV1.gt3x.RData.csv\"\n",
    "ggir_data = compare_dataframes.load_ggir_output(ggir_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(compare_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_df, outputdata_trimmed = compare_dataframes.compare(\n",
    "                                    ggir_dataframe= ggir_data,\n",
    "                                    wristpy_dataframe=test_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdata_trimmed = outputdata_trimmed.with_columns(\n",
    "    ggir_data[\"ENMO\"].alias(\"GGIR_ENMO\"),\n",
    "    ggir_data[\"anglez\"].alias(\"GGIR_anglez\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NW_flag_rolling_mean = outputdata_trimmed[\"non-wear flag\"].rolling_mean(window_size = 2160)\n",
    "NW_flag_rolling_mean = NW_flag_rolling_mean.map_elements(lambda x: 1 if x > 0.25 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_calc_nonwear = outputdata_trimmed.filter(outputdata_trimmed[\"non-wear flag\"] == 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_calc_nonwear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(df, col1, col2):\n",
    "    squared_error = (df[col1] - df[col2]) ** 2\n",
    "    mse = squared_error.mean()\n",
    "    return mse\n",
    "\n",
    "\n",
    "\n",
    "mse_anglez = compute_mse(metrics_calc_nonwear, \"anglez\", \"GGIR_anglez\")\n",
    "mse_enmo = compute_mse(metrics_calc_nonwear, \"ENMO\", \"GGIR_ENMO\")\n",
    "\n",
    "print(f\"MSE ENMO: {mse_enmo}\", f\"MSE Angle Z: {mse_anglez}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angz_diff = (metrics_calc_nonwear[\"anglez\"] - metrics_calc_nonwear[\"GGIR_anglez\"])\n",
    "\n",
    "plt.hist((angz_diff), bins=90)\n",
    "plt.xlabel('angz_diff')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of angz_diff')\n",
    "plt.yscale('log')\n",
    "plt.xlim(-100,100)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angz_diff.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.offline as offline\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=metrics_calc_nonwear[\"timestamp\"], y=metrics_calc_nonwear[\"anglez\"], mode='lines', name='anglez', line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=metrics_calc_nonwear[\"timestamp\"], y=metrics_calc_nonwear[\"GGIR_anglez\"], mode='lines', name='GGIR_anglez', line=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x=metrics_calc_nonwear[\"timestamp\"], y=angz_diff, mode='lines', name='angz_diff', line=dict(color='green')))\n",
    "fig.show()\n",
    "\n",
    "# Save the plot as an HTML file\n",
    "#offline.plot(fig, filename='comparison_plot.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_df_days = compare_dataframes.select_days(df = difference_df,\n",
    "                                                       start_day = 2, \n",
    "                                                       end_day = 20)\n",
    "ggir_data_days = compare_dataframes.select_days(df = ggir_data,\n",
    "                                                   start_day=  2,\n",
    "                                                   end_day= 20)\n",
    "outputdata_trimmed_days = compare_dataframes.select_days(df = outputdata_trimmed,\n",
    "                                                            start_day= 2,\n",
    "                                                            end_day= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "(difference_df_days[\"anglez\"] **2).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dataframes.plot_diff(\n",
    "                outputdata_trimmed = outputdata_trimmed_days, \n",
    "                ggir_dataframe = ggir_data_days, \n",
    "                difference_df = difference_df_days,\n",
    "                measures=\"anglez\", \n",
    "                opacity= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(compare_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIND DAYS**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wristpy_out = pl.read_csv(input_path)\n",
    "wristpy_time = pl.Series(wristpy_out[\"time\"])\n",
    "wristpy_datetime = wristpy_time.str.to_datetime(time_unit=\"ns\")\n",
    "wristpy_out = wristpy_out.replace(\"time\", wristpy_datetime)\n",
    "import datetime as dt\n",
    "ordinal_dates = (wristpy_out[\"time\"].dt.timestamp() / (24 * 60 * 60*1e6) + 719163).floor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wristpy_out = wristpy_out.with_columns(ordinal_dates.alias(\"ordinal_dates\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wristpy_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IAT dates to ordinal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IAT_PCIAT_dates = pl.read_csv(\"/Users/adam.santorelli/Downloads/HBN_IAT_Kaggle2024/IAT_PCIAT_Dates/IAT_PCIAT_dates_sorted_AS.csv\")\n",
    "IAT_dates = IAT_PCIAT_dates[\"IAT_Date\"].str.to_datetime(format=\"%m/%d/%y\")\n",
    "PCIAT_dates = IAT_PCIAT_dates[\"PCIAT_Date\"].str.to_datetime(format=\"%m/%d/%y\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAT_PCIAT_dates_comp = IAT_PCIAT_dates.with_columns(IAT_dates.alias(\"IAT_Date\"), PCIAT_dates.alias(\"PCIAT_Date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAT_PCIAT_dates_comp_filter = IAT_PCIAT_dates_comp.filter(\n",
    "    (IAT_PCIAT_dates_comp[\"IAT_Date\"].is_not_null()) |\n",
    "    (IAT_PCIAT_dates_comp[\"PCIAT_Date\"].is_not_null())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAT_PCIAT_dates_comp_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAT_ordinal =(IAT_PCIAT_dates_comp_filter[\"IAT_Date\"].dt.timestamp() / (24 * 60 * 60*1e6) + 719163).floor()\n",
    "PCIAT_ordinal =(IAT_PCIAT_dates_comp_filter[\"PCIAT_Date\"].dt.timestamp() / (24 * 60 * 60*1e6) + 719163).floor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAT_dates_df = pl.DataFrame({\"ID\": IAT_PCIAT_dates_comp_filter[\"ID\"], \"IAT_ordinal\": IAT_ordinal, \"PCIAT_ordinal\": PCIAT_ordinal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAT_dates_df.write_csv(\"/Users/adam.santorelli/Downloads/HBN_IAT_Kaggle2024/IAT_PCIAT_dates_ordinal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAT_dates_df = pl.read_csv(\"/Users/adam.santorelli/Downloads/HBN_IAT_Kaggle2024/IAT_PCIAT_dates_ordinal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAT_ordinal_count = IAT_dates_df[\"IAT_ordinal\"].count()\n",
    "PCIAT_ordinal_count = IAT_dates_df[\"PCIAT_ordinal\"].count()\n",
    "\n",
    "\n",
    "non_null_count = IAT_dates_df.filter((IAT_dates_df[\"IAT_ordinal\"].is_not_null()) & (IAT_dates_df[\"PCIAT_ordinal\"].is_not_null())).count()\n",
    "non_null_count,IAT_ordinal_count, PCIAT_ordinal_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get relative dates for wristpy_out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_csv(\n",
    "    \"/Users/adam.santorelli/Downloads/HBN_IAT_Kaggle2024/IAT_PCIAT_dates_ordinal.csv\"\n",
    ")\n",
    "\n",
    "# Get the IDs\n",
    "ids = df[\"ID\"].tolist()\n",
    "\n",
    "# Find all directories that end with \"_output\"\n",
    "directories = glob.glob(\"/Users/adam.santorelli/Downloads/wristpy_out/*_output\")\n",
    "\n",
    "# Filter the directories based on the IDs from the Excel file\n",
    "matching_directories = [\n",
    "    d for d in directories if os.path.basename(d).split(\"_\")[0] in ids\n",
    "]\n",
    "\n",
    "# matching_directories now contains all directories that match the IDs from the Excel file\n",
    "\n",
    "# Save the list of matching directories as a new CSV file\n",
    "pd.DataFrame(matching_directories, columns=[\"Directory\"]).to_csv(\n",
    "    \"/Users/adam.santorelli/Downloads/wristpy_out/matching_directories.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_directories_sorted = sorted(matching_directories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matching_directories_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = matching_directories_sorted.index(\"/Users/adam.santorelli/Downloads/wristpy_out/NDARMT703JGP_output\")\n",
    "matching_directories_sorted2 = matching_directories_sorted[idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the matching directories\n",
    "for directory in matching_directories_sorted2:\n",
    "    # Get the ID from the directory name\n",
    "    id = os.path.basename(directory).split(\"_\")[0]\n",
    "\n",
    "    matching_row = df[df[\"ID\"] == id]\n",
    "\n",
    "    # Read the CSV file\n",
    "    wristpy_out = pl.read_csv(f\"{directory}/{id}_metrics_out.csv\")\n",
    "\n",
    "    # Convert the time column to ordinal dates\n",
    "    wristpy_time = pl.Series(wristpy_out[\"time\"])\n",
    "    wristpy_time = pl.Series(wristpy_out[\"time\"])\n",
    "    wristpy_datetime = wristpy_time.str.to_datetime(time_unit=\"ns\")\n",
    "\n",
    "    ordinal_dates = (\n",
    "        wristpy_out[\"time\"].dt.timestamp() / (24 * 60 * 60 * 1e6) + 719163\n",
    "    ).floor()\n",
    "\n",
    "    relative_date_IAT = ordinal_dates - matching_row[\"IAT_ordinal\"].to_numpy()\n",
    "    relative_date_PCIAT = ordinal_dates - matching_row[\"PCIAT_ordinal\"].to_numpy()\n",
    "    relative_date_IAT_df = pl.DataFrame({\"relative_date_IAT\": relative_date_IAT})\n",
    "    relative_date_PCIAT_df = pl.DataFrame({\"relative_date_PCIAT\": relative_date_PCIAT})\n",
    "    wristpy_out = wristpy_out.with_columns(relative_date_IAT_df)\n",
    "    wristpy_out = wristpy_out.with_columns(relative_date_PCIAT_df)\n",
    "\n",
    "    # Save the CSV file to the new directory\n",
    "    wristpy_out.write_csv(\n",
    "        f\"/Users/adam.santorelli/Downloads/wristpy_out_full_dates/{id}_metrics_out_full.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# get the mean and std distribution for participants\n",
    "\n",
    "# Define the directory to search for CSV files\n",
    "dir_path = \"/Users/adam.santorelli/Downloads/wristpy_out_full_dates/\"\n",
    "\n",
    "# Search for all .csv files in the directory\n",
    "file_list = glob.glob(dir_path + \"*.csv\")\n",
    "\n",
    "# Initialize lists to store mean and std values\n",
    "mean_values = []\n",
    "std_values = []\n",
    "\n",
    "# Search the directories for CSV files\n",
    "for file in file_list:\n",
    "   \n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"Processing {file}\")\n",
    "    # Grab the columns IAT_dates and PCIAT_dates\n",
    "    iat_dates = df[\"relative_date_IAT\"]\n",
    "    pciat_dates = df[\"relative_date_PCIAT\"]\n",
    "\n",
    "    # Compute the mean and std of the columns\n",
    "    mean_iat = iat_dates.mean()\n",
    "    mean_pciat = pciat_dates.mean()\n",
    "    std_iat = iat_dates.std()\n",
    "    std_pciat = pciat_dates.std()\n",
    "\n",
    "    # Append the mean and std values to the lists\n",
    "    mean_values.append((mean_iat, mean_pciat))\n",
    "    std_values.append((std_iat, std_pciat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the mean_values and std_values lists\n",
    "date_data_avg = pd.DataFrame({'mean_iat': [mean[0] for mean in mean_values],\n",
    "                     'mean_pciat': [mean[1] for mean in mean_values],\n",
    "                     'std_iat': [std[0] for std in std_values],\n",
    "                     'std_pciat': [std[1] for std in std_values]})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "date_data_avg.to_csv('mean_std_values.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=date_data_avg[\"mean_pciat\"], nbinsx=100)])\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Mean PCIAT Dates\",\n",
    "    yaxis_title=\"Frequency\",\n",
    "    title=\"Histogram of Mean IAT Dates\"\n",
    ")\n",
    "fig.write_html(\"histogram_PCIAT.html\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define source and destination directories\n",
    "src_dir = '/Users/adam.santorelli//Downloads/ggir_raw_outputs_group1'\n",
    "dst_dir = '/Users/adam.santorelli//Downloads/ggir_raw_outputs_group2'\n",
    "\n",
    "# Get list of all files in source directory\n",
    "src_files = os.listdir(src_dir)\n",
    "\n",
    "# Iterate over each file in source directory and copy to destination directory\n",
    "for file_name in src_files:\n",
    "    full_file_name = os.path.join(src_dir, file_name)\n",
    "    if os.path.isfile(full_file_name):\n",
    "        shutil.copy2(full_file_name, dst_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Sensor data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import actfast\n",
    "\n",
    "subject1 = actfast.read_actigraph_gt3x(test_config.path_input) #this could be anypath to a gt3x file\n",
    "\n",
    "light_df = pl.from_dict(\n",
    "    {\n",
    "    \"light_time\": subject1[\"timeseries\"][\"lux\"][\"datetime\"],\n",
    "    \"lux\": subject1[\"timeseries\"][\"lux\"][\"lux\"]\n",
    "})\n",
    "\n",
    "time_tmp = pl.Series(light_df[\"light_time\"])\n",
    "time_light = pl.from_epoch(time_tmp, time_unit=\"ns\").alias(\"time\")\n",
    "light_df = light_df.with_columns(time_light)\n",
    "light_df_mean = metrics_calc.moving_mean_fast(pl.DataFrame(light_df[\"lux\"]), light_df[\"time\"], 5)\n",
    "\n",
    "battery_df = pl.from_dict(\n",
    "    {\n",
    "    \"battery_time\": subject1[\"timeseries\"][\"battery_voltage\"][\"datetime\"],\n",
    "    \"battery\": subject1[\"timeseries\"][\"battery_voltage\"][\"battery_voltage\"]\n",
    "    })\n",
    "\n",
    "cap_sense_df = pl.from_dict(\n",
    "    {\n",
    "        \"cap_sense_time\": subject1[\"timeseries\"][\"capsense\"][\"datetime\"],\n",
    "        \"cap_sense_flag\": subject1[\"timeseries\"][\"capsense\"][\"capsense\"]    \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
